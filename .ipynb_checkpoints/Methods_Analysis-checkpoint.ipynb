{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>بسم الله الرحمن الرحيم</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"*__*\")\n",
    "df.head()\n",
    "df.shape\n",
    "sometimes you need to change the data type so info will tell you the right and the wrong data type\n",
    "df.info()\n",
    "df.describe()\n",
    "\n",
    "sometimes you need to change the data type so info will tell you the right and the wrong data type\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable contains true and false values in this data frame\n",
    "# missing_data = df.isna()\n",
    "# for col in missing_data:\n",
    "#     print(\"Column: \",col)\n",
    "#     print(missing_data[col].value_counts())\n",
    "#     print(\"-\"*50+\"\\n\")\n",
    "\n",
    "# another way df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['column_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't Forget n in the begning\n",
    "# df.nunique()\n",
    "# for large data set use sum(df.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type of specefic column\n",
    "\n",
    "# df['End Time'] = pd.to_datetime(df['End Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use means to fill in missing values\n",
    "# mean_texture = df['texture_mean'].mean()  good for simple code\n",
    "\n",
    "# df['texture_mean'].fillna(df['texture_mean'].mean(),inplace=True)\n",
    "\n",
    "# df['smoothness_mean'].fillna(df['smoothness_mean'].mean(),inplace=True)\n",
    "\n",
    "# df['symmetry_mean'].fillna(df['symmetry_mean'].mean(),inplace=True)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# GooooooD Idea\n",
    "\n",
    "# df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.duplicated()\n",
    "# sum(df.duplicated()) to know how many duplicated value\n",
    "\n",
    "# df.drop_duplicates(inplace=True)\n",
    "# to check again\n",
    "# sum(df.duplicated())\n",
    "\n",
    "# good way\n",
    "# df_white.duplicated().value_counts() True & False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing pandas \n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "# plot relationship between temperature and electrical output\n",
    "# df.plot(x='temperature', y='energy_output', kind='scatter');\n",
    "\n",
    "# # plot distribution of humidity\n",
    "# df['humidity'].hist();\n",
    "\n",
    "# df['temperature'].plot(kind='box');\n",
    "\n",
    "\n",
    "# Multible Box Plot\n",
    "# df[['storeA','storeB','storeC']].plot(kind='box')\n",
    "\n",
    "\n",
    "\n",
    "# pd.qcut(df1['popn'],q=10).value_counts().plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another_Way\n",
    "\n",
    "# df.hist(figsize=(8, 8)); will remove other non numerical data\n",
    "\n",
    "# --------\n",
    "# total sales for the last month\n",
    "\n",
    "# df.iloc[196:, 1:].sum()\n",
    "# df.iloc[196:, 1:].sum().plot(kind='bar');\n",
    "\n",
    "# from 196 to the end of row and 1: from column one to the edn\n",
    "# -----------\n",
    "\n",
    "# worst week for store C\n",
    "# df[df['storeC'] == df['storeC'].min()]\n",
    "# or df['storeC'].idxmin()\n",
    "\n",
    "# ---------\n",
    "\n",
    "# Important\n",
    "# total sales during most recent 3 month period\n",
    "# df.tail(20) show us the last three months start from 2017/12 to 2018/2\n",
    "# the last month\n",
    "# last_three_months = df[df['week'] >= '2017-12-01']\n",
    "# last_three_months.iloc[:, 1:].sum()  # exclude sum of week column\n",
    "# short way df[df['week']>='2017-12-01'].sum()\n",
    "# --------------------\n",
    "# Visualize The same Data\n",
    "# sales = df[df['week'] == '2016-03-13']\n",
    "# sales.iloc[0, 1:].plot(kind='bar');\n",
    "# ind = df_a['education'].value_counts().index\n",
    "# df_a['education'].value_counts()[ind].plot(kind='bar') \n",
    "# ------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat Array With numpy\n",
    "\n",
    "# color_white = np.repeat('white', df.shape[0])\n",
    "# white_df['color'] = color_white\"\n",
    "\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Column\n",
    "# df=df.rename(columns = {'two':'new_name'})\n",
    "\n",
    "# ---------\n",
    "\n",
    "# to_csv حتي لا يقوم بعمل اندكس\n",
    "# df.to_csv('clean_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_Cars Project \"GOOD START \"\n",
    "# df_18.head()\n",
    "# df_18.shape\n",
    "# df_18.info()\n",
    "# print(\"2008 Duplicated\",df_08.duplicated().sum())\n",
    "# print(\"2018 Unique Values\",df_18.nunique().sum())\n",
    "# print(\"2018 Null Value\",df_18.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "# df.drop(['B', 'C'], axis=1)\n",
    "# drop rows\n",
    "# df.drop([0, 1])\n",
    "# df_08.drop(['cert_region'],axis = 1,inplace=True)\n",
    "\n",
    "# -------\n",
    "# IF there's is any NA\n",
    "# df_18.isnull().sum() \n",
    "\n",
    "\n",
    "# NA DROP\n",
    "# df_08.dropna(inplace=True)\n",
    "# -------------\n",
    "# checks if any of columns in 2008 have null values - should print False\n",
    "# df_08.isnull().sum().any()\n",
    "# ---------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicated Values\n",
    "\n",
    "# print(df_08.duplicated().sum())\n",
    "# drop duplicates in both datasets\n",
    "# df_08.drop_duplicates(inplace=True)\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Int From String\n",
    "# Extract int from strings in the 2008 cyl column\n",
    "\n",
    "\n",
    "# df_08['cyl'] = df_08['cyl'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOOOOOOD STEP\n",
    "# Very Important\n",
    "\n",
    "\n",
    "# df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(np.random.randn(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Loop To Replace Specefic Information\n",
    "# asap_list = ['Immediately', 'As soon as possible', 'Upon hiring','Immediate', 'Immediate employment']\n",
    "\n",
    "# for i in asap_list:\n",
    "#     df_clean['StartDate'].replace({i:'ASAP'}, inplace=True)\n",
    "\n",
    "# clean\n",
    "# df_clean['Body weight (kg)'] = df_clean['Body weight (kg)'].str.replace('!', '.')\n",
    "\n",
    "\n",
    "# df_clean['Animal'] = df_clean['Animal'].str[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone_number:  ['951-719-9170']\n",
      "---------------------------------------------\n",
      "\n",
      "Email:  ['ZoeWellish@superrito.com']\n"
     ]
    }
   ],
   "source": [
    "# Regular Expressions\n",
    "# a = \"951-719-9170ZoeWellish@superrito.com\"\n",
    "# import re\n",
    "# print(\"Phone_number: \",re.findall(r'[0-9-]+',a))\n",
    "# print(\"-\"*45+\"\\n\")\n",
    "# print(\"Email: \",re.findall(r'[a-zA-Z]+@[a-zA-Z.]+',a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hb_08 = df[df['fuel'].str.contain('/')]\n",
    "# df1 = hb_08.copy()\n",
    "# df2 = hb_08.copy()\n",
    "# columns to split by \"/\"\n",
    "# split_columns = ['fuel', 'air_pollution_score', 'city_mpg', 'hwy_mpg', 'cmb_mpg', 'greenhouse_gas_score']\n",
    "\n",
    "# # apply split function to each column of each dataframe copy\n",
    "# for c in split_columns:\n",
    "#     df1[c] = df1[c].apply(lambda x: x.split(\"/\")[0])\n",
    "#     df2[c] = df2[c].apply(lambda x: x.split(\"/\")[1])\n",
    "\n",
    "# new_rows = df1.append(df2)\n",
    "# orginal.drop(hb_08.index, inplace=True)\n",
    "# original = df.append(new_rows,igonore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New_idea\n",
    "# alt_08 = df_08.query('fuel in [\"CNG\", \"ethanol\"]').model.nunique()\n",
    "# alt_08\n",
    "\n",
    "# ------------------\n",
    "\n",
    "\n",
    "# df_08[(df_08['fuel']=='CNG') | (df_08['fuel']=='ethanol')].model.nunique()\n",
    "\n",
    "\n",
    "# plt.bar([\"2008\", \"2018\"], [alt_08, alt_18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Trip Duration'].describe() It's good to convert numeric data to category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling Data Steps\n",
    "\n",
    "- Low Quality Data IS Dirty\n",
    "\n",
    "- Untidy Data Is messy\n",
    "\n",
    "# Common data quality issues include:\n",
    "\n",
    "- missing data, like the missing height value for Juan Nan.\n",
    "- invalid data, like a cell having an impossible value, e.g., like negative height value for Kwasi. Having \"inches\" and - \n",
    "\"centimetres\" in the height entries is technically invalid as well, since the datatype for height becomes a string when those are present. The datatype for height should be integer or float.\n",
    "- inaccurate data, like Jane actually being 58 inches tall, not 55 inches tall.\n",
    "- inconsistent data, like using different units for height (inches and centimetres).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A dataset is messy or tidy depending on how rows, columns, and tables are matched up with observations,\n",
    "variables, and types. In tidy data:\n",
    "\n",
    "- Each variable forms a column.\n",
    "- Each observation forms a row.\n",
    "- Each type of observational unit forms a table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Tidiness\n",
    "\n",
    "- Improving tidiness means transforming the dataset so that each variable is a column,\n",
    "- each observation is a row, and each type of observational unit is a table.\n",
    "\n",
    "- Define Code Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirty data\n",
    "- also known as low quality data. Low quality data has content issues.With Content outlier Value,Duplicated\n",
    "\n",
    "### Messy data\n",
    "- also known as untidy data. Untidy data has structural issues. Column Instead OF Rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [5, 10, 15, 5, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.47213595499958"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
